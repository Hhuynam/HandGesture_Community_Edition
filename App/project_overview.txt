import cv2
import module_hand_tracking
import module_mouse_control
import module_ui
import pyautogui
import numpy as np
from module_gesture_recognition import predict_gesture
from module_brightness import BrightnessControl
from module_volume import VolumeControl
from module_zoom import ZoomControl

# Khởi tạo webcam
cap = cv2.VideoCapture(0)
screen_width, screen_height = pyautogui.size()

# Khởi tạo các module
hand_tracker = module_hand_tracking.HandTracker()
mouse_controller = module_mouse_control.MouseController(screen_width, screen_height)
ui = module_ui.HandTrackingUI()
brightness_control = BrightnessControl()
volume_control = VolumeControl()
zoom_control = ZoomControl()

# Biến trạng thái điều khiển
current_control = None  # Trạng thái mặc định, chưa chọn điều khiển

# Hàm xử lý các nút trên giao diện
def adjust_volume():
    global current_control
    current_control = "volume"
    print("Chế độ Volume được kích hoạt!")

def adjust_brightness():
    global current_control
    current_control = "brightness"
    print("Chế độ Brightness được kích hoạt!")

def adjust_zoom():
    global current_control
    current_control = "zoom"
    print("Chế độ Zoom được kích hoạt!")

# Gắn hàm vào các nút giao diện
ui.btn_volume.config(command=adjust_volume)
ui.btn_brightness.config(command=adjust_brightness)
ui.btn_zoom.config(command=adjust_zoom)

# Hàm cập nhật video và xử lý logic
def update_video():
    ret, frame = cap.read()
    if not ret:
        ui.root.after(10, update_video)
        return

    # Xử lý hiển thị video trên giao diện
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    frame_resized = cv2.resize(frame_rgb, (ui.canvas_video.winfo_width(), ui.canvas_video.winfo_height()))
    ui.update_video_canvas(frame_resized)

    # Phát hiện bàn tay
    results = hand_tracker.detect_hands(frame)
    if results.multi_hand_landmarks:
        for landmarks in results.multi_hand_landmarks:
            # Xử lý tùy theo chế độ được chọn
            if current_control == "volume":
                distance = calculate_distance(landmarks)
                volume_control.adjust_volume(distance)
                print(f"Điều chỉnh âm lượng với khoảng cách: {distance:.2f}")

            elif current_control == "brightness":
                distance = calculate_distance(landmarks)
                brightness_control.adjust_brightness(distance)
                print(f"Điều chỉnh độ sáng với khoảng cách: {distance:.2f}")

            elif current_control == "zoom":
                distance = calculate_distance(landmarks)
                zoom_control.adjust_zoom(distance)
                print(f"Điều chỉnh zoom với khoảng cách: {distance:.2f}")

            # Hiển thị feedback bàn tay lên giao diện
            ui.update_feedback_canvas(landmarks)

    ui.root.after(10, update_video)  # Lặp lại sau 10ms

def calculate_distance(landmarks):
    """Tính khoảng cách giữa ngón cái và ngón trỏ."""
    index_tip = landmarks.landmark[module_hand_tracking.mp_hands.HandLandmark.INDEX_FINGER_TIP]
    thumb_tip = landmarks.landmark[module_hand_tracking.mp_hands.HandLandmark.THUMB_TIP]
    return ((index_tip.x - thumb_tip.x) ** 2 + (index_tip.y - thumb_tip.y) ** 2) ** 0.5

# Khởi chạy ứng dụng
ui.run(update_video)
cap.release()
cv2.destroyAllWindows()
---
#module_brightness.py
import screen_brightness_control as sbc

class BrightnessControl:
    def __init__(self):
        self.prev_distance = None

    def adjust_brightness(self, distance):
        current_brightness = sbc.get_brightness(display=0)[0]

        if self.prev_distance is None:
            self.prev_distance = distance
            return

        threshold = 0.02  # Giảm mức nhạy cảm

        if distance > self.prev_distance + threshold:
            sbc.set_brightness(min(current_brightness + 5, 100))
            print("Tăng độ sáng")
        elif distance < self.prev_distance - threshold:
            sbc.set_brightness(max(current_brightness - 5, 0))
            print("Giảm độ sáng")

        self.prev_distance = distance
---
#module_gesture_recognition.py
import cv2
import numpy as np
import tensorflow as tf
from tensorflow import keras

# Đường dẫn tới mô hình đã huấn luyện
model_path = r"D:\Project\HandGesture_Community_Edition\models\phanloai_cuchitay.h5"

# Tải mô hình
try:
    model = keras.models.load_model(model_path, compile=False)
    print("Model loaded successfully!")
except Exception as e:
    print(f"Error loading model: {e}")
    model = None

# Danh sách nhãn của mô hình
labels = ['fist','open_palm','thumbs_up']
# Hàm dự đoán cử chỉ từ ảnh đầu vào
def predict_gesture(image):
    if model is None:
        return "Unknown"
    
    try:
        # Chuyển ảnh sang định dạng RGB (nếu cần)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # Resize ảnh về kích thước mà mô hình yêu cầu
        image = cv2.resize(image, (256, 256))
        
        # Chuẩn hóa ảnh (giá trị từ 0 đến 1)
        image = np.expand_dims(image, axis=0) / 255.0
        
        # Dự đoán cử chỉ từ mô hình
        prediction = model.predict(image, verbose=0)[0]
        
        # Trả về nhãn có xác suất cao nhất
        predicted_label = labels[np.argmax(prediction)]
        return predicted_label
    except Exception as e:
        print(f"Error during prediction: {e}")
        return "Unknown"
---
# module_hand_tracking.py
import cv2
import mediapipe as mp

mp_hands = mp.solutions.hands
mp_draw = mp.solutions.drawing_utils

class HandTracker:
    def __init__(self, min_detection_confidence=0.7, min_tracking_confidence=0.7):
        self.hands = mp_hands.Hands(min_detection_confidence=min_detection_confidence,
                                    min_tracking_confidence=min_tracking_confidence)
    
    def detect_hands(self, frame):
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        return self.hands.process(frame_rgb)
    
    def is_five_fingers_up(self, hand_landmarks):
        tips = [mp_hands.HandLandmark.THUMB_TIP, mp_hands.HandLandmark.INDEX_FINGER_TIP,
                mp_hands.HandLandmark.MIDDLE_FINGER_TIP, mp_hands.HandLandmark.RING_FINGER_TIP,
                mp_hands.HandLandmark.PINKY_TIP]
        
        pips = [mp_hands.HandLandmark.THUMB_IP, mp_hands.HandLandmark.INDEX_FINGER_PIP,
                mp_hands.HandLandmark.MIDDLE_FINGER_PIP, mp_hands.HandLandmark.RING_FINGER_PIP,
                mp_hands.HandLandmark.PINKY_PIP]
        
        count = sum(1 for tip, pip in zip(tips, pips) if hand_landmarks.landmark[tip].y < hand_landmarks.landmark[pip].y)
        return count == 5 
---
# module_mouse_control.py
import pyautogui
import numpy as np

class MouseController:
    def __init__(self, screen_width, screen_height):
        self.screen_width = screen_width
        self.screen_height = screen_height
        self.pos_history = []
        self.click_state = False
    
    def move_mouse(self, index_tip):
        mouse_x = int(index_tip.x * self.screen_width)
        mouse_y = int(index_tip.y * self.screen_height)
        
        self.pos_history.append((mouse_x, mouse_y))
        if len(self.pos_history) > 5:
            self.pos_history.pop(0)
        
        smooth_x = int(np.mean([p[0] for p in self.pos_history]))
        smooth_y = int(np.mean([p[1] for p in self.pos_history]))
        
        pyautogui.moveTo(smooth_x, smooth_y)
    
    def click_mouse(self, is_five_fingers_up):
        if is_five_fingers_up and not self.click_state:
            pyautogui.click()
            self.click_state = True
        elif not is_five_fingers_up:
            self.click_state = False
---
#module_ui.py
import tkinter as tk
from PIL import Image, ImageTk
import mediapipe as mp

class HandTrackingUI:
    def __init__(self):
        self.root = tk.Tk()
        self.root.title("Hand Gesture Control")
        #self.root.geometry("860x550")
        self.root.geometry("1200x800")
        self.root.columnconfigure(0, weight=3)
        self.root.columnconfigure(1, weight=1)
        self.root.rowconfigure(0, weight=1)
        self.root.rowconfigure(1, weight=1)

        # Đặt icon cho ứng dụng
        icon_path = r"D:\Project\HandGesture_Community_Edition\Assets\logo\hand_gesture_logo.ico"
        self.root.iconbitmap(icon_path)

        # Frame chứa video
        self.frame_video = tk.Frame(self.root, bg="black", bd=2, relief="sunken")
        self.frame_video.grid(row=0, column=0, rowspan=4, padx=10, pady=10, sticky="nsew")

        self.label_video = tk.Label(self.frame_video, text="Video Feed", font=("Arial", 14, "bold"), bg="black", fg="white")
        self.label_video.pack(anchor="n", pady=5)

        self.canvas_video = tk.Canvas(self.frame_video, bg="black")
        self.canvas_video.pack(fill="both", expand=True)

        # Frame hướng dẫn user
        self.frame_guiding = tk.Frame(self.root, bg="orange", bd=2, relief="sunken")
        self.frame_guiding.grid(row=1, column=1, padx=10, pady=10, sticky="nsew")

        self.label_guiding = tk.Label(self.frame_guiding, text="User Guiding", font=("Arial", 14, "bold"), bg="orange", fg="black")
        self.label_guiding.pack(anchor="n", pady=5)

        self.label_gesture_info = tk.Label(self.frame_guiding, text="Đang chờ nhận diện...", font=("Arial", 12), bg="orange", fg="black")
        self.label_gesture_info.pack(pady=5)

        # Frame điều khiển
        self.frame_control_panel = tk.Frame(self.root, bg="lightgreen", bd=2, relief="sunken")
        self.frame_control_panel.grid(row=0, column=1, padx=10, pady=10, sticky="nsew")

        self.label_control_panel = tk.Label(self.frame_control_panel, text="Control Panel", font=("Arial", 14, "bold"), bg="lightgreen", fg="black")
        self.label_control_panel.pack(anchor="n", pady=5)

        self.btn_volume = tk.Button(self.frame_control_panel, text="Volume", font=("Arial", 12), bg="white", fg="black", command=self.adjust_volume)
        self.btn_volume.pack(pady=5, padx=10, fill="x")

        self.btn_brightness = tk.Button(self.frame_control_panel, text="Brightness", font=("Arial", 12), bg="white", fg="black", command=self.adjust_brightness)
        self.btn_brightness.pack(pady=5, padx=10, fill="x")

        self.btn_zoom = tk.Button(self.frame_control_panel, text="Zoom", font=("Arial", 12), bg="white", fg="black", command=self.adjust_zoom)
        self.btn_zoom.pack(pady=5, padx=10, fill="x")

        # Thêm hiệu ứng hover
        for btn in [self.btn_volume, self.btn_brightness, self.btn_zoom]:
            btn.bind("<Enter>", lambda e, b=btn: b.config(bg="gray", fg="white"))
            btn.bind("<Leave>", lambda e, b=btn: b.config(bg="white", fg="black"))
            btn.bind("<ButtonPress>", lambda e, b=btn: b.config(bg="darkgray"))
            btn.bind("<ButtonRelease>", lambda e, b=btn: b.config(bg="gray"))

        # Frame chứa feedback
        self.frame_feedback = tk.Frame(self.root, bg="lightblue", bd=2, relief="sunken")
        self.frame_feedback.grid(row=2, column=1, padx=10, pady=10, sticky="nsew")

        self.label_feedback = tk.Label(self.frame_feedback, text="Hand Gesture Feedback", font=("Arial", 14, "bold"), bg="lightblue", fg="black")
        self.label_feedback.pack(anchor="n", pady=5)

        self.canvas_feedback = tk.Canvas(self.frame_feedback, bg="lightblue")
        self.canvas_feedback.pack(padx=10, pady=10, fill="both", expand=True)
        
    def adjust_volume(self):
        print("Adjusting Volume")

    def adjust_brightness(self):
        print("Adjusting Brightness")

    def adjust_zoom(self):
        print("Adjusting Zoom")

    def update_video_canvas(self, frame):
        img = Image.fromarray(frame)
        img_tk = ImageTk.PhotoImage(image=img)
        self.canvas_video.create_image(0, 0, anchor="nw", image=img_tk)
        self.canvas_video.img_tk = img_tk  # Tránh bị mất ảnh

    def update_feedback_canvas(self, hand_landmarks):
        self.canvas_feedback.delete("all")
    
        width, height = self.canvas_feedback.winfo_width(), self.canvas_feedback.winfo_height()
    
        for lm in hand_landmarks.landmark:
            lx, ly = int(lm.x * width), int(lm.y * height)
            self.canvas_feedback.create_oval(lx-4, ly-4, lx+4, ly+4, fill="red")

        index_tip = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.INDEX_FINGER_TIP]
        self.canvas_feedback.create_oval(int(index_tip.x * width) - 6,
                                         int(index_tip.y * height) - 6,
                                         int(index_tip.x * width) + 6,
                                         int(index_tip.y * height) + 6,
                                         fill="yellow")

        for connection in mp.solutions.hands.HAND_CONNECTIONS:
            start_idx, end_idx = connection
            start = hand_landmarks.landmark[start_idx]
            end = hand_landmarks.landmark[end_idx]

            sx, sy = int(start.x * width), int(start.y * height)
            ex, ey = int(end.x * width), int(end.y * height)

            self.canvas_feedback.create_line(sx, sy, ex, ey, fill="white", width=2)

    def update_gesture_info(self, gesture_name):
        self.label_gesture_info.config(text=f"Hệ thống nhận diện: {gesture_name}", font=("Arial", 12, "bold"))

    def update_button_color(self, gesture_name):
        """Cập nhật màu sắc của các nút điều khiển khi nhận diện cử chỉ"""
        # Đặt lại màu nền các nút về mặc định
        self.btn_volume.config(bg="white")
        self.btn_brightness.config(bg="white")
        self.btn_zoom.config(bg="white")

        if gesture_name == "thumbs_up":
            self.btn_volume.config(bg="red")  # Đổi màu nút Volume thành đỏ
        elif gesture_name == "fist":
            self.btn_brightness.config(bg="red")  # Đổi màu nút Brightness thành đỏ
        elif gesture_name == "open_palm":
            self.btn_zoom.config(bg="red")  # Đổi màu nút Zoom thành đỏ
    
    def run(self, update_func):
        self.root.after(10, update_func)
        self.root.mainloop()
---
#module_volume.py
import pyautogui

class VolumeControl:
    def __init__(self):
        self.prev_distance = None

    def adjust_volume(self, distance):
        if self.prev_distance is None:
            self.prev_distance = distance
            return

        threshold = 0.02  # Chỉ thay đổi khi khoảng cách tăng/giảm lớn hơn mức này

        if distance > self.prev_distance + threshold:
            pyautogui.press("volumeup")
            print("🔊 Tăng âm lượng")
        elif distance < self.prev_distance - threshold:
            pyautogui.press("volumedown")
            print("🔉 Giảm âm lượng")

        self.prev_distance = distance
---
#module_zoom.py
import pyautogui

class ZoomControl:
    def __init__(self):
        self.prev_distance = None

    def adjust_zoom(self, distance):
        if self.prev_distance is None:
            self.prev_distance = distance
            return

        if distance > self.prev_distance + 5:
            pyautogui.hotkey("ctrl", "+")
            print("Zoom In")
        elif distance < self.prev_distance - 5:
            pyautogui.hotkey("ctrl", "-")
            print("Zoom Out")

        self.prev_distance = distance
