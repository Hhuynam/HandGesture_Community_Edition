import cv2
import module_hand_tracking
import module_mouse_control
import module_ui
import pyautogui
import numpy as np
from module_gesture_recognition import predict_gesture
from module_brightness import BrightnessControl
from module_volume import VolumeControl
from module_zoom import ZoomControl

# Kh·ªüi t·∫°o webcam
cap = cv2.VideoCapture(0)
screen_width, screen_height = pyautogui.size()

# Kh·ªüi t·∫°o c√°c module
hand_tracker = module_hand_tracking.HandTracker()
mouse_controller = module_mouse_control.MouseController(screen_width, screen_height)
ui = module_ui.HandTrackingUI()
brightness_control = BrightnessControl()
volume_control = VolumeControl()
zoom_control = ZoomControl()

# Bi·∫øn tr·∫°ng th√°i ƒëi·ªÅu khi·ªÉn
current_control = None  # Tr·∫°ng th√°i m·∫∑c ƒë·ªãnh, ch∆∞a ch·ªçn ƒëi·ªÅu khi·ªÉn

# H√†m x·ª≠ l√Ω c√°c n√∫t tr√™n giao di·ªán
def adjust_volume():
    global current_control
    current_control = "volume"
    print("Ch·∫ø ƒë·ªô Volume ƒë∆∞·ª£c k√≠ch ho·∫°t!")

def adjust_brightness():
    global current_control
    current_control = "brightness"
    print("Ch·∫ø ƒë·ªô Brightness ƒë∆∞·ª£c k√≠ch ho·∫°t!")

def adjust_zoom():
    global current_control
    current_control = "zoom"
    print("Ch·∫ø ƒë·ªô Zoom ƒë∆∞·ª£c k√≠ch ho·∫°t!")

# G·∫Øn h√†m v√†o c√°c n√∫t giao di·ªán
ui.btn_volume.config(command=adjust_volume)
ui.btn_brightness.config(command=adjust_brightness)
ui.btn_zoom.config(command=adjust_zoom)

# H√†m c·∫≠p nh·∫≠t video v√† x·ª≠ l√Ω logic
def update_video():
    ret, frame = cap.read()
    if not ret:
        ui.root.after(10, update_video)
        return

    # X·ª≠ l√Ω hi·ªÉn th·ªã video tr√™n giao di·ªán
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    frame_resized = cv2.resize(frame_rgb, (ui.canvas_video.winfo_width(), ui.canvas_video.winfo_height()))
    ui.update_video_canvas(frame_resized)

    # Ph√°t hi·ªán b√†n tay
    results = hand_tracker.detect_hands(frame)
    if results.multi_hand_landmarks:
        for landmarks in results.multi_hand_landmarks:
            # X·ª≠ l√Ω t√πy theo ch·∫ø ƒë·ªô ƒë∆∞·ª£c ch·ªçn
            if current_control == "volume":
                distance = calculate_distance(landmarks)
                volume_control.adjust_volume(distance)
                print(f"ƒêi·ªÅu ch·ªânh √¢m l∆∞·ª£ng v·ªõi kho·∫£ng c√°ch: {distance:.2f}")

            elif current_control == "brightness":
                distance = calculate_distance(landmarks)
                brightness_control.adjust_brightness(distance)
                print(f"ƒêi·ªÅu ch·ªânh ƒë·ªô s√°ng v·ªõi kho·∫£ng c√°ch: {distance:.2f}")

            elif current_control == "zoom":
                distance = calculate_distance(landmarks)
                zoom_control.adjust_zoom(distance)
                print(f"ƒêi·ªÅu ch·ªânh zoom v·ªõi kho·∫£ng c√°ch: {distance:.2f}")

            # Hi·ªÉn th·ªã feedback b√†n tay l√™n giao di·ªán
            ui.update_feedback_canvas(landmarks)

    ui.root.after(10, update_video)  # L·∫∑p l·∫°i sau 10ms

def calculate_distance(landmarks):
    """T√≠nh kho·∫£ng c√°ch gi·ªØa ng√≥n c√°i v√† ng√≥n tr·ªè."""
    index_tip = landmarks.landmark[module_hand_tracking.mp_hands.HandLandmark.INDEX_FINGER_TIP]
    thumb_tip = landmarks.landmark[module_hand_tracking.mp_hands.HandLandmark.THUMB_TIP]
    return ((index_tip.x - thumb_tip.x) ** 2 + (index_tip.y - thumb_tip.y) ** 2) ** 0.5

# Kh·ªüi ch·∫°y ·ª©ng d·ª•ng
ui.run(update_video)
cap.release()
cv2.destroyAllWindows()
---
#module_brightness.py
import screen_brightness_control as sbc

class BrightnessControl:
    def __init__(self):
        self.prev_distance = None

    def adjust_brightness(self, distance):
        current_brightness = sbc.get_brightness(display=0)[0]

        if self.prev_distance is None:
            self.prev_distance = distance
            return

        threshold = 0.02  # Gi·∫£m m·ª©c nh·∫°y c·∫£m

        if distance > self.prev_distance + threshold:
            sbc.set_brightness(min(current_brightness + 5, 100))
            print("TƒÉng ƒë·ªô s√°ng")
        elif distance < self.prev_distance - threshold:
            sbc.set_brightness(max(current_brightness - 5, 0))
            print("Gi·∫£m ƒë·ªô s√°ng")

        self.prev_distance = distance
---
#module_gesture_recognition.py
import cv2
import numpy as np
import tensorflow as tf
from tensorflow import keras

# ƒê∆∞·ªùng d·∫´n t·ªõi m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán
model_path = r"D:\Project\HandGesture_Community_Edition\models\phanloai_cuchitay.h5"

# T·∫£i m√¥ h√¨nh
try:
    model = keras.models.load_model(model_path, compile=False)
    print("Model loaded successfully!")
except Exception as e:
    print(f"Error loading model: {e}")
    model = None

# Danh s√°ch nh√£n c·ªßa m√¥ h√¨nh
labels = ['fist','open_palm','thumbs_up']
# H√†m d·ª± ƒëo√°n c·ª≠ ch·ªâ t·ª´ ·∫£nh ƒë·∫ßu v√†o
def predict_gesture(image):
    if model is None:
        return "Unknown"
    
    try:
        # Chuy·ªÉn ·∫£nh sang ƒë·ªãnh d·∫°ng RGB (n·∫øu c·∫ßn)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # Resize ·∫£nh v·ªÅ k√≠ch th∆∞·ªõc m√† m√¥ h√¨nh y√™u c·∫ßu
        image = cv2.resize(image, (256, 256))
        
        # Chu·∫©n h√≥a ·∫£nh (gi√° tr·ªã t·ª´ 0 ƒë·∫øn 1)
        image = np.expand_dims(image, axis=0) / 255.0
        
        # D·ª± ƒëo√°n c·ª≠ ch·ªâ t·ª´ m√¥ h√¨nh
        prediction = model.predict(image, verbose=0)[0]
        
        # Tr·∫£ v·ªÅ nh√£n c√≥ x√°c su·∫•t cao nh·∫•t
        predicted_label = labels[np.argmax(prediction)]
        return predicted_label
    except Exception as e:
        print(f"Error during prediction: {e}")
        return "Unknown"
---
# module_hand_tracking.py
import cv2
import mediapipe as mp

mp_hands = mp.solutions.hands
mp_draw = mp.solutions.drawing_utils

class HandTracker:
    def __init__(self, min_detection_confidence=0.7, min_tracking_confidence=0.7):
        self.hands = mp_hands.Hands(min_detection_confidence=min_detection_confidence,
                                    min_tracking_confidence=min_tracking_confidence)
    
    def detect_hands(self, frame):
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        return self.hands.process(frame_rgb)
    
    def is_five_fingers_up(self, hand_landmarks):
        tips = [mp_hands.HandLandmark.THUMB_TIP, mp_hands.HandLandmark.INDEX_FINGER_TIP,
                mp_hands.HandLandmark.MIDDLE_FINGER_TIP, mp_hands.HandLandmark.RING_FINGER_TIP,
                mp_hands.HandLandmark.PINKY_TIP]
        
        pips = [mp_hands.HandLandmark.THUMB_IP, mp_hands.HandLandmark.INDEX_FINGER_PIP,
                mp_hands.HandLandmark.MIDDLE_FINGER_PIP, mp_hands.HandLandmark.RING_FINGER_PIP,
                mp_hands.HandLandmark.PINKY_PIP]
        
        count = sum(1 for tip, pip in zip(tips, pips) if hand_landmarks.landmark[tip].y < hand_landmarks.landmark[pip].y)
        return count == 5 
---
# module_mouse_control.py
import pyautogui
import numpy as np

class MouseController:
    def __init__(self, screen_width, screen_height):
        self.screen_width = screen_width
        self.screen_height = screen_height
        self.pos_history = []
        self.click_state = False
    
    def move_mouse(self, index_tip):
        mouse_x = int(index_tip.x * self.screen_width)
        mouse_y = int(index_tip.y * self.screen_height)
        
        self.pos_history.append((mouse_x, mouse_y))
        if len(self.pos_history) > 5:
            self.pos_history.pop(0)
        
        smooth_x = int(np.mean([p[0] for p in self.pos_history]))
        smooth_y = int(np.mean([p[1] for p in self.pos_history]))
        
        pyautogui.moveTo(smooth_x, smooth_y)
    
    def click_mouse(self, is_five_fingers_up):
        if is_five_fingers_up and not self.click_state:
            pyautogui.click()
            self.click_state = True
        elif not is_five_fingers_up:
            self.click_state = False
---
#module_ui.py
import tkinter as tk
from PIL import Image, ImageTk
import mediapipe as mp

class HandTrackingUI:
    def __init__(self):
        self.root = tk.Tk()
        self.root.title("Hand Gesture Control")
        #self.root.geometry("860x550")
        self.root.geometry("1200x800")
        self.root.columnconfigure(0, weight=3)
        self.root.columnconfigure(1, weight=1)
        self.root.rowconfigure(0, weight=1)
        self.root.rowconfigure(1, weight=1)

        # ƒê·∫∑t icon cho ·ª©ng d·ª•ng
        icon_path = r"D:\Project\HandGesture_Community_Edition\Assets\logo\hand_gesture_logo.ico"
        self.root.iconbitmap(icon_path)

        # Frame ch·ª©a video
        self.frame_video = tk.Frame(self.root, bg="black", bd=2, relief="sunken")
        self.frame_video.grid(row=0, column=0, rowspan=4, padx=10, pady=10, sticky="nsew")

        self.label_video = tk.Label(self.frame_video, text="Video Feed", font=("Arial", 14, "bold"), bg="black", fg="white")
        self.label_video.pack(anchor="n", pady=5)

        self.canvas_video = tk.Canvas(self.frame_video, bg="black")
        self.canvas_video.pack(fill="both", expand=True)

        # Frame h∆∞·ªõng d·∫´n user
        self.frame_guiding = tk.Frame(self.root, bg="orange", bd=2, relief="sunken")
        self.frame_guiding.grid(row=1, column=1, padx=10, pady=10, sticky="nsew")

        self.label_guiding = tk.Label(self.frame_guiding, text="User Guiding", font=("Arial", 14, "bold"), bg="orange", fg="black")
        self.label_guiding.pack(anchor="n", pady=5)

        self.label_gesture_info = tk.Label(self.frame_guiding, text="ƒêang ch·ªù nh·∫≠n di·ªán...", font=("Arial", 12), bg="orange", fg="black")
        self.label_gesture_info.pack(pady=5)

        # Frame ƒëi·ªÅu khi·ªÉn
        self.frame_control_panel = tk.Frame(self.root, bg="lightgreen", bd=2, relief="sunken")
        self.frame_control_panel.grid(row=0, column=1, padx=10, pady=10, sticky="nsew")

        self.label_control_panel = tk.Label(self.frame_control_panel, text="Control Panel", font=("Arial", 14, "bold"), bg="lightgreen", fg="black")
        self.label_control_panel.pack(anchor="n", pady=5)

        self.btn_volume = tk.Button(self.frame_control_panel, text="Volume", font=("Arial", 12), bg="white", fg="black", command=self.adjust_volume)
        self.btn_volume.pack(pady=5, padx=10, fill="x")

        self.btn_brightness = tk.Button(self.frame_control_panel, text="Brightness", font=("Arial", 12), bg="white", fg="black", command=self.adjust_brightness)
        self.btn_brightness.pack(pady=5, padx=10, fill="x")

        self.btn_zoom = tk.Button(self.frame_control_panel, text="Zoom", font=("Arial", 12), bg="white", fg="black", command=self.adjust_zoom)
        self.btn_zoom.pack(pady=5, padx=10, fill="x")

        # Th√™m hi·ªáu ·ª©ng hover
        for btn in [self.btn_volume, self.btn_brightness, self.btn_zoom]:
            btn.bind("<Enter>", lambda e, b=btn: b.config(bg="gray", fg="white"))
            btn.bind("<Leave>", lambda e, b=btn: b.config(bg="white", fg="black"))
            btn.bind("<ButtonPress>", lambda e, b=btn: b.config(bg="darkgray"))
            btn.bind("<ButtonRelease>", lambda e, b=btn: b.config(bg="gray"))

        # Frame ch·ª©a feedback
        self.frame_feedback = tk.Frame(self.root, bg="lightblue", bd=2, relief="sunken")
        self.frame_feedback.grid(row=2, column=1, padx=10, pady=10, sticky="nsew")

        self.label_feedback = tk.Label(self.frame_feedback, text="Hand Gesture Feedback", font=("Arial", 14, "bold"), bg="lightblue", fg="black")
        self.label_feedback.pack(anchor="n", pady=5)

        self.canvas_feedback = tk.Canvas(self.frame_feedback, bg="lightblue")
        self.canvas_feedback.pack(padx=10, pady=10, fill="both", expand=True)
        
    def adjust_volume(self):
        print("Adjusting Volume")

    def adjust_brightness(self):
        print("Adjusting Brightness")

    def adjust_zoom(self):
        print("Adjusting Zoom")

    def update_video_canvas(self, frame):
        img = Image.fromarray(frame)
        img_tk = ImageTk.PhotoImage(image=img)
        self.canvas_video.create_image(0, 0, anchor="nw", image=img_tk)
        self.canvas_video.img_tk = img_tk  # Tr√°nh b·ªã m·∫•t ·∫£nh

    def update_feedback_canvas(self, hand_landmarks):
        self.canvas_feedback.delete("all")
    
        width, height = self.canvas_feedback.winfo_width(), self.canvas_feedback.winfo_height()
    
        for lm in hand_landmarks.landmark:
            lx, ly = int(lm.x * width), int(lm.y * height)
            self.canvas_feedback.create_oval(lx-4, ly-4, lx+4, ly+4, fill="red")

        index_tip = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.INDEX_FINGER_TIP]
        self.canvas_feedback.create_oval(int(index_tip.x * width) - 6,
                                         int(index_tip.y * height) - 6,
                                         int(index_tip.x * width) + 6,
                                         int(index_tip.y * height) + 6,
                                         fill="yellow")

        for connection in mp.solutions.hands.HAND_CONNECTIONS:
            start_idx, end_idx = connection
            start = hand_landmarks.landmark[start_idx]
            end = hand_landmarks.landmark[end_idx]

            sx, sy = int(start.x * width), int(start.y * height)
            ex, ey = int(end.x * width), int(end.y * height)

            self.canvas_feedback.create_line(sx, sy, ex, ey, fill="white", width=2)

    def update_gesture_info(self, gesture_name):
        self.label_gesture_info.config(text=f"H·ªá th·ªëng nh·∫≠n di·ªán: {gesture_name}", font=("Arial", 12, "bold"))

    def update_button_color(self, gesture_name):
        """C·∫≠p nh·∫≠t m√†u s·∫Øc c·ªßa c√°c n√∫t ƒëi·ªÅu khi·ªÉn khi nh·∫≠n di·ªán c·ª≠ ch·ªâ"""
        # ƒê·∫∑t l·∫°i m√†u n·ªÅn c√°c n√∫t v·ªÅ m·∫∑c ƒë·ªãnh
        self.btn_volume.config(bg="white")
        self.btn_brightness.config(bg="white")
        self.btn_zoom.config(bg="white")

        if gesture_name == "thumbs_up":
            self.btn_volume.config(bg="red")  # ƒê·ªïi m√†u n√∫t Volume th√†nh ƒë·ªè
        elif gesture_name == "fist":
            self.btn_brightness.config(bg="red")  # ƒê·ªïi m√†u n√∫t Brightness th√†nh ƒë·ªè
        elif gesture_name == "open_palm":
            self.btn_zoom.config(bg="red")  # ƒê·ªïi m√†u n√∫t Zoom th√†nh ƒë·ªè
    
    def run(self, update_func):
        self.root.after(10, update_func)
        self.root.mainloop()
---
#module_volume.py
import pyautogui

class VolumeControl:
    def __init__(self):
        self.prev_distance = None

    def adjust_volume(self, distance):
        if self.prev_distance is None:
            self.prev_distance = distance
            return

        threshold = 0.02  # Ch·ªâ thay ƒë·ªïi khi kho·∫£ng c√°ch tƒÉng/gi·∫£m l·ªõn h∆°n m·ª©c n√†y

        if distance > self.prev_distance + threshold:
            pyautogui.press("volumeup")
            print("üîä TƒÉng √¢m l∆∞·ª£ng")
        elif distance < self.prev_distance - threshold:
            pyautogui.press("volumedown")
            print("üîâ Gi·∫£m √¢m l∆∞·ª£ng")

        self.prev_distance = distance
---
#module_zoom.py
import pyautogui

class ZoomControl:
    def __init__(self):
        self.prev_distance = None

    def adjust_zoom(self, distance):
        if self.prev_distance is None:
            self.prev_distance = distance
            return

        if distance > self.prev_distance + 5:
            pyautogui.hotkey("ctrl", "+")
            print("Zoom In")
        elif distance < self.prev_distance - 5:
            pyautogui.hotkey("ctrl", "-")
            print("Zoom Out")

        self.prev_distance = distance
